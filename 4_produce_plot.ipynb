{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Scripts\n",
    "Copyright (c) 2025 University of Salerno SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "Run this whole Jupyter to produce the paper plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import os\n",
    "import re\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import signal\n",
    "import glob\n",
    "from scripts.utils import SIGMOOutputAnalyzer\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "SINGLE_COL_FIGSIZE=(7, 5)\n",
    "HALF_COL_FIGSIZE=(3.5, 5)\n",
    "\n",
    "# Create a function to set the font size for specific figures\n",
    "def set_font_size(ax, size):\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                 ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell only for single-node and portability experiments assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmo_df = pd.read_csv('./out/SIGMO/sigmo_results.csv')\n",
    "sigmo_df = sigmo_df.sort_values(by='n_refinement_steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5\n",
    "Summary of the distribution of candidate set sizes for each refinement iteration. The box represents the distribution of the candidates set sizes for each node and aligns with the left axis, whereas the line indicates the total number of candidates, aligning with the right axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "candidates_sizes = sigmo_df[sigmo_df['find_all']]['candidates_sizes']\n",
    "# Convert strings into numeric arrays (Nodes Ã— Iterations)\n",
    "candidate_matrix = np.array(candidates_sizes.apply(lambda x: [int(i) for i in x.split('-')]).tolist()).T\n",
    "\n",
    "data_for_scatter = pd.DataFrame({\n",
    "    'Iteration': np.tile(np.arange(candidate_matrix.shape[1]), candidate_matrix.shape[0]),\n",
    "    'Node': np.repeat(np.arange(candidate_matrix.shape[0]), candidate_matrix.shape[1]),\n",
    "    'CandidateSize': candidate_matrix.flatten()\n",
    "})\n",
    "data_for_scatter['Iteration'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 16\n",
    "COLOR=sns.color_palette()[0]\n",
    "fig, ax1 = plt.subplots(figsize=SINGLE_COL_FIGSIZE)\n",
    "\n",
    "# Function to get outliers\n",
    "def find_outliers(group):\n",
    "    values = group['CandidateSize']\n",
    "    q1 = values.quantile(0.25)\n",
    "    q3 = values.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return group[(values < lower) | (values > upper)]\n",
    "\n",
    "outliers_df = data_for_scatter.groupby('Iteration', group_keys=False).apply(find_outliers)\n",
    "\n",
    "sns.boxplot(data=data_for_scatter, \n",
    "            x='Iteration', \n",
    "            y='CandidateSize', \n",
    "            flierprops=dict(marker='.', markersize=4), \n",
    "            ax=ax1, \n",
    "            color=\"lightgray\",\n",
    "            width=0.7,\n",
    "            showfliers=False,\n",
    "            )\n",
    "sns.stripplot(\n",
    "    data=outliers_df,\n",
    "    x='Iteration',\n",
    "    y='CandidateSize',\n",
    "    ax=ax1,\n",
    "    jitter=True,\n",
    "    size=4,\n",
    "    color='lightgray',\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "ax1.set_xlabel('Refinement Iterations', fontsize=FONTSIZE)\n",
    "ax1.set_ylabel('# Candidates per Node', fontsize=FONTSIZE)\n",
    "set_font_size(ax1, FONTSIZE)\n",
    "\n",
    "# Secondary axis for the total sum of candidates per iteration\n",
    "ax2 = ax1.twinx()\n",
    "total_candidates = data_for_scatter.groupby('Iteration')['CandidateSize'].sum().reset_index()\n",
    "\n",
    "sns.lineplot(data=total_candidates['CandidateSize'], ax=ax2, marker='^', linestyle='-', label='Total Candidates', linewidth=2.5, markersize=7, alpha=.7, color=COLOR)\n",
    "ax2.set_ylabel('# Total Candidates', fontsize=FONTSIZE, color=COLOR)\n",
    "ax2.tick_params(axis='y', labelcolor=COLOR)\n",
    "set_font_size(ax2, FONTSIZE)\n",
    "ax1.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "# ax2.grid(True, axis='y', linestyle='--', alpha=0.5, color=sns.color_palette()[0])\n",
    "ax2.grid(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/candidates_size.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6\n",
    "Comparison of filter and join time per each refinement iteration on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 18\n",
    "fig, axs = plt.subplots(figsize=SINGLE_COL_FIGSIZE)\n",
    "\n",
    "filter_time = [result.filter_gpu_time / 1000 for result in sigmo_df[sigmo_df['find_all']].itertuples()]\n",
    "join_time = [result.join_gpu_time / 1000 for result in sigmo_df[sigmo_df['find_all']].itertuples()]\n",
    "total_time = [result.total_gpu_time / 1000 for result in sigmo_df[sigmo_df['find_all']].itertuples()]\n",
    "\n",
    "# Create a DataFrame\n",
    "iterations = list(range(1, len(filter_time) + 1))\n",
    "data = pd.DataFrame({\n",
    "    'Iterations': iterations,\n",
    "    'Filter Time': filter_time,\n",
    "    'Join Time': join_time\n",
    "})\n",
    "\n",
    "# Calculate total time\n",
    "data['Total Time'] = total_time\n",
    "\n",
    "# Melt the DataFrame to long format\n",
    "data_melted = data.melt(id_vars='Iterations', value_vars=['Filter Time', 'Join Time'], var_name='Type', value_name='Time')\n",
    "\n",
    "\n",
    "# Create the line plot\n",
    "sns.lineplot(data=data_melted, x='Iterations', y='Time', hue='Type', marker='o', markersize=10, ax=axs)\n",
    "\n",
    "# Add the total time bars\n",
    "axs.bar(data['Iterations'], data['Total Time'], color='gray', alpha=0.4, label='Total Time')\n",
    "\n",
    "# Add labels and title\n",
    "axs.set_xlabel('Refinement Iterations')\n",
    "axs.set_ylabel('Time (s)')\n",
    "\n",
    "# get the lowest bar and add a label to mark that is the lowest, add also an arrow\n",
    "lowest_bar = min(data['Total Time'])\n",
    "axs.annotate('Lowest Time', xy=(data['Iterations'][data['Total Time'].idxmin()], lowest_bar),\n",
    "             xytext=(data['Iterations'][data['Total Time'].idxmin()] - 1, lowest_bar + lowest_bar * .5),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05), fontsize=FONTSIZE)\n",
    "\n",
    "\n",
    "# Add legend\n",
    "axs.legend(fontsize=FONTSIZE)\n",
    "set_font_size(axs, 18)\n",
    "\n",
    "# Show the plot\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/filter_join_time.pdf', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 7\n",
    "Total execution time of SIGMo across refinement iterations, grouped by query graph diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter_res = {}\n",
    "for file in glob.glob('./out/SIGMO/logs/diameter/*.log'):\n",
    "  diameter, iteration = file.split('/')[-1].replace('.log', '').replace('sigmo_d', '').split('_')\n",
    "  if diameter not in diameter_res:\n",
    "    diameter_res[diameter] = []\n",
    "  with open(file, 'r') as f:\n",
    "    content = f.read()\n",
    "  diameter_res[diameter].append((iteration, content))\n",
    "\n",
    "for d in diameter_res:\n",
    "  tmp = sorted(diameter_res[d], key=lambda x: int(x[0]))\n",
    "  diameter_res[d] = [x[1] for x in tmp]\n",
    "\n",
    "# sort the diameter_res by diameter\n",
    "diameter_res = dict(sorted(diameter_res.items(), key=lambda x: int(x[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "FONTSIZE = 16\n",
    "LAST_ITERATION=8\n",
    "fig, axs = plt.subplots(2, len(diameter_res) // 2, figsize=(20, 4.5), sharex=True, sharey=False)\n",
    "\n",
    "if len(diameter_res) == 1:\n",
    "  axs = [axs]  # Ensure axs is iterable when there's only one plot\n",
    "\n",
    "def format_ticks(value, _):\n",
    "    return f'{value:.2}'  # Format to 3 significant digits\n",
    "\n",
    "\n",
    "for idx, (diameter, results) in enumerate(diameter_res.items()):\n",
    "  total_times = []\n",
    "  for output in results:\n",
    "    parser = SIGMOOutputAnalyzer(output)\n",
    "    total_times.append(parser.total_time / 1000)  # Convert ms to seconds\n",
    "\n",
    "  iterations = list(range(1, LAST_ITERATION + 1))\n",
    "  total_times = total_times[:len(iterations)]\n",
    "  axs.flat[idx].plot(iterations, total_times, marker='o')\n",
    "  # Highlight the minimum time in red\n",
    "  min_time = min(total_times)\n",
    "  min_index = total_times.index(min_time) + (1 if diameter != 4 else 0)  # Add 1 to match iteration index\n",
    "  axs.flat[idx].plot(min_index, min_time, marker='o', color='red')\n",
    "  \n",
    "  # Set x-ticks for all subplots\n",
    "  axs.flat[idx].set_xticks(iterations)\n",
    "  axs.flat[idx].grid(True, linestyle='--', alpha=0.5)\n",
    "  axs.flat[idx].set_title(f'Diameter {diameter}', fontsize=FONTSIZE)\n",
    "  \n",
    "  # Apply the y-tick formatter\n",
    "  axs.flat[idx].yaxis.set_major_formatter(FuncFormatter(format_ticks))\n",
    "  set_font_size(axs.flat[idx], FONTSIZE)\n",
    "\n",
    "# Adjust spacing between horizontal plots\n",
    "plt.subplots_adjust(wspace=0.3)  # Increase the vertical space between rows\n",
    "\n",
    "handles = [\n",
    "    Line2D([0], [0], marker='o', color='blue', label='Total Time', markersize=8, linestyle='None'),\n",
    "    Line2D([0], [0], marker='o', color='red', label='Min Time', markersize=10, linestyle='None')\n",
    "]\n",
    "fig.legend(handles=handles, loc='upper center', fontsize=FONTSIZE, ncol=2, bbox_to_anchor=(0.5, 1.03), frameon=False)\n",
    "# Add a single x-axis label\n",
    "fig.text(0.5, 0.005, 'Refinement Iterations', ha='center', fontsize=FONTSIZE)\n",
    "# Add a single y-axis label\n",
    "fig.text(0.00, 0.5, 'Total Time (s)', va='center', rotation='vertical', fontsize=FONTSIZE)\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.025, 1, 0.95])\n",
    "fig.savefig('./out/plots/total_time_per_diameter.pdf', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 8\n",
    "Profiling of the NVIDIA V100S GPU occupancy during the SIGMo runtime with six refinement iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILING_SAMPLE = 10 # ms\n",
    "def extract_profiled_region(X, Y, time_per_sample, left_padding_ms=500, right_padding_ms=100):\n",
    "    X = np.array(X)\n",
    "\n",
    "    # Find the first and last nonzero indices\n",
    "    nonzero_indices = np.where(X > 0)[0]\n",
    "    if len(nonzero_indices) == 0:\n",
    "        raise ValueError(\"No nonzero profiling data found in X.\")\n",
    "\n",
    "    start_idx = nonzero_indices[0]\n",
    "    end_idx = nonzero_indices[-1] + 1  # Include the last nonzero element\n",
    "\n",
    "    # Extract the active region\n",
    "    active_region = X[start_idx:end_idx]\n",
    "\n",
    "    # Determine number of samples for Y milliseconds\n",
    "    num_samples = int(Y / time_per_sample)\n",
    "    left_padding_samples = int(left_padding_ms / time_per_sample)\n",
    "    right_padding_samples = int(right_padding_ms / time_per_sample)\n",
    "\n",
    "    # if num_samples > len(active_region):\n",
    "    #     raise ValueError(\"Y exceeds the available profiled region.\")\n",
    "\n",
    "    # Define padded start and end indices\n",
    "    padded_start = max(0, start_idx - left_padding_samples)\n",
    "    padded_end = min(len(X), start_idx + num_samples + right_padding_samples)\n",
    "\n",
    "    return X[padded_start:padded_end]\n",
    "\n",
    "with open('./out/SIGMO/logs/gpu_metrics/dcgmi.log', 'r') as f:\n",
    "  dcgmi_output = f.read()\n",
    "\n",
    "with open('./out/SIGMO/logs/gpu_metrics/sigmo.log', 'r') as f:\n",
    "  sigmo_output = f.read()\n",
    "\n",
    "# Parse the dcgmi output into a DataFrame\n",
    "data = [line for line in dcgmi_output.strip().split(\"\\n\") if len(line.split()) > 2]  # Extract rows\n",
    "\n",
    "gpu_utilization = [float(row.split()[2]) for row in data]  \n",
    "\n",
    "# Print the DataFrame (optional)\n",
    "p = SIGMOOutputAnalyzer(sigmo_output)\n",
    "gpu_utilization = extract_profiled_region(gpu_utilization, p.total_time, PROFILING_SAMPLE, 200, 100)\n",
    "\n",
    "gpu_df = pd.DataFrame()\n",
    "\n",
    "# Add a time column (assuming each row corresponds to 10 ms)\n",
    "gpu_df['timestamp'] = [i * PROFILING_SAMPLE for i in range(len(gpu_utilization))]\n",
    "gpu_df['gpu_util'] = gpu_utilization\n",
    "gpu_df['gpu_util'] = gpu_df['gpu_util'] * 100\n",
    "gpu_df.to_csv('./out/SIGMO/gpu_util.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 18 \n",
    "OFFSET = 140\n",
    "\n",
    "fig, axs = plt.subplots(figsize=SINGLE_COL_FIGSIZE)\n",
    "\n",
    "operations = [\n",
    "    {'name': 'Filter', 'start': p.setup_data_host_time , 'end': (p.setup_data_host_time + p.filter_gpu_time) +OFFSET, 'color': 'skyblue'},\n",
    "    {'name': 'Mapping', 'start': (p.setup_data_host_time + p.filter_gpu_time ) + OFFSET, 'end': (p.setup_data_host_time + p.filter_gpu_time + p.mapping_host_time) + OFFSET + 20, 'color': 'salmon'},\n",
    "    {'name': 'Join', 'start': (p.setup_data_host_time + p.filter_gpu_time + p.mapping_host_time + OFFSET + 20), 'end': (p.setup_data_host_time + p.filter_host_time + p.mapping_host_time + p.join_host_time), 'color': 'lightgreen'},\n",
    "    # {'name': 'Other', 'start': (p.setup_data_host_time + p.filter_host_time + p.mapping_host_time + p.join_host_time), 'end': p.total_time, 'color': 'lightgray'}\n",
    "]\n",
    "\n",
    "# Plot the GPU utilization as a line\n",
    "sns.lineplot(data=gpu_df, x='timestamp', y='gpu_util', ax=axs)\n",
    "\n",
    "# Loop through each operation to fill the corresponding region with its color\n",
    "for op in operations:\n",
    "    # Create a mask for timestamps within the operation's interval\n",
    "    mask = (gpu_df['timestamp'] >= op['start']) & (gpu_df['timestamp'] <= op['end'])\n",
    "    \n",
    "    # Fill the area under the curve for this operation\n",
    "    axs.fill_between(\n",
    "        gpu_df.loc[mask, 'timestamp'], \n",
    "        gpu_df.loc[mask, 'gpu_util'], \n",
    "        color=op['color'], \n",
    "        alpha=0.4, \n",
    "        label=op['name']\n",
    "    )\n",
    "\n",
    "# Find the first and last nonzero GPU utilization timestamps\n",
    "nonzero_mask = gpu_df['gpu_util'] > 0\n",
    "if nonzero_mask.any():\n",
    "    first_nonzero_ts = gpu_df.loc[nonzero_mask, 'timestamp'].iloc[0] - 20\n",
    "    last_nonzero_ts = gpu_df.loc[nonzero_mask, 'timestamp'].iloc[-1]\n",
    "    \n",
    "    # Draw vertical dashed lines at the first and last nonzero values\n",
    "    axs.axvline(first_nonzero_ts, color='black', linestyle='--')\n",
    "\n",
    "    # Get overall min and max timestamps from the data\n",
    "    min_ts = gpu_df['timestamp'].min()\n",
    "    max_ts = gpu_df['timestamp'].max()\n",
    "    \n",
    "    # Highlight regions before the first nonzero and after the last nonzero\n",
    "    axs.text(first_nonzero_ts, .5, 'Data Initialization', transform=axs.get_xaxis_transform(), \n",
    "             rotation=90, verticalalignment='center', horizontalalignment='right', color='black', fontsize=FONTSIZE)\n",
    "\n",
    "# Add labels and title\n",
    "axs.set_xlabel(\"Application Runtime (ms)\", fontsize=14)\n",
    "axs.set_ylabel(\"GPU Occupancy (%)\", fontsize=FONTSIZE)\n",
    "axs.grid(True)\n",
    "axs.legend(fontsize=FONTSIZE-2)\n",
    "set_font_size(axs, FONTSIZE)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/gpu_utilization.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 9\n",
    "Instruction Roofline of SIGMo execution with six refinement iterations on NVIDIA V100S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv('./out/SIGMO/logs/gpu_metrics/metrics.csv')\n",
    "\n",
    "kernels = ['FilterCandidatesKernel', 'RefineCandidatesKernel', 'JoinCandidatesKernel', 'generateGMCR']\n",
    "\n",
    "# drop nan kernel names\n",
    "metrics_df = metrics_df[~metrics_df['Kernel Name'].isna()]\n",
    "\n",
    "# keep only entries that have in the column Kernel Name at least one of the kernels\n",
    "metrics_df = metrics_df[metrics_df['Kernel Name'].str.contains('|'.join(kernels))]\n",
    "\n",
    "for substring, new_name in zip(kernels, ['Filter', 'Filter', 'Join', 'Mapping']):\n",
    "  metrics_df.loc[metrics_df['Kernel Name'].str.contains(substring), 'Kernel Name'] = new_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = metrics_df.groupby(['ID','Kernel Name'])\n",
    "group_names = groups.groups.keys()\n",
    "\n",
    "def fetch_metric_unit(df, metric):\n",
    "  return float(df.loc[df['Metric Name'] == metric]['Metric Value'].values[0].replace(',', '')), df.loc[df['Metric Name'] == metric]['Metric Unit'].values[0]\n",
    "\n",
    "def parse_memory(val, unit):\n",
    "  if unit == 'Kbyte':\n",
    "    return float(val) * 1024\n",
    "  elif unit == 'Mbyte':\n",
    "    return float(val) * 1024 ** 2\n",
    "  elif unit == 'Gbyte':\n",
    "    return float(val) * 1024 ** 3\n",
    "  else:\n",
    "    return float(val)\n",
    "\n",
    "def parse_time(val, unit):\n",
    "  if unit == 'msecond':\n",
    "    return float(val) / 1000\n",
    "  elif unit == 'usecond':\n",
    "    return float(val) / 1000 ** 2\n",
    "  elif unit == 'nsecond':\n",
    "    return float(val) / 1000 ** 3\n",
    "  else:\n",
    "    return float(val)\n",
    "\n",
    "metrics_refined_df = pd.DataFrame(columns=['kernel', 'ii_global', 'it'])\n",
    "\n",
    "for name, g in groups:\n",
    "  instructions = int(g.loc[g['Metric Name'] == \"inst_executed\"]['Metric Value'].values[0].replace(',', ''))\n",
    "  \n",
    "  total_bytes = 0\n",
    "  total_bytes += fetch_metric_unit(g, \"dram__sectors_read.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"dram__sectors_write.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"lts__t_sectors.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"lts__t_sectors_data_ecc.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"lts__t_sectors_srcunit_tex.sum\")[0] * 32\n",
    "  # total_bytes += fetch_metric_unit(g, \"l1tex__m_l1tex2xbar_write_sectors_mem_lg_op_st.sum\")[0] * 32\n",
    "  # total_bytes += fetch_metric_unit(g, \"l1tex__m_xbar2l1tex_read_sectors_mem_lg_op_ld.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_lsu_mem_global_op_atom.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_lsu_mem_local_op_ld.sum\")[0] * 32\n",
    "  total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_lsu_mem_local_op_st.sum\")[0] * 32\n",
    "  # total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_tex_mem_surface_op_ld.sum\")[0] * 32\n",
    "  # total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_tex_mem_surface_op_red.sum\")[0] * 32\n",
    "  # total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_tex_mem_surface_op_st.sum\")[0] * 32\n",
    "  # total_bytes += fetch_metric_unit(g, \"l1tex__t_sectors_pipe_tex_mem_texture.sum\")[0] * 32\n",
    "  \n",
    "  instruction_intensity_global = instructions / (total_bytes)\n",
    "  \n",
    "  time = parse_time(float(g.loc[g['Metric Name'] == \"gpu__time_duration.sum\"]['Metric Value'].values[0]), g.loc[g['Metric Name'] == \"gpu__time_duration.sum\"]['Metric Unit'].values[0])\n",
    "  \n",
    "  instruction_throughput = (instructions / time) / 1e9\n",
    "  if instruction_throughput < 1: continue\n",
    "  print(f\"{name=}\\t{total_bytes=}\\t{time=:.4f}\\t{instructions=:12}\\t{instruction_intensity_global=}\\t{instruction_throughput=}\")\n",
    "  metrics_refined_df.loc[len(metrics_refined_df)] = [name[1], instruction_intensity_global, instruction_throughput]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 18\n",
    "fig, axs = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "peak = 80 * 32 * 2 * 1.53 # GFLOP/s\n",
    "peak_nofma = peak / 2 # GFLOP/s\n",
    "l1_peak = 437.5 * 32 # GB/s\n",
    "l2_peak = 93.6 * 32 # GB/s\n",
    "hbm_peak = 25.9 * 32 # GB/s\n",
    "\n",
    "# ==== PLOTTING SECTION ====\n",
    "# Create log-space x-axis for roofline curves\n",
    "x_vals = np.logspace(-2, 3, 500)\n",
    "\n",
    "# Compute memory ceilings (sloped lines)\n",
    "roof_hbm = np.minimum(hbm_peak * x_vals, peak_nofma)\n",
    "roof_l2 = np.minimum(l2_peak * x_vals, peak_nofma)\n",
    "roof_l1 = np.minimum(l1_peak * x_vals, peak_nofma)\n",
    "\n",
    "# Plot sloped memory rooflines\n",
    "axs.plot(x_vals, roof_hbm, linestyle='--', color='black', label=\"HBM Roof\", linewidth=1.1)\n",
    "axs.plot(x_vals, roof_l2, linestyle='-.', color='black', label=\"L2 Roof\", linewidth=1)\n",
    "axs.plot(x_vals, roof_l1, linestyle='dotted', color='black', label=\"L1 Roof\", linewidth=1.1)\n",
    "\n",
    "# Plot flat compute peak\n",
    "axs.axhline(y=peak_nofma, color='black', linestyle='-', label=\"Compute Roof\", linewidth=1.2)\n",
    "\n",
    "instruction_intensity = metrics_refined_df['ii_global'].values\n",
    "instruction_throughput = metrics_refined_df['it'].values\n",
    "kernel_names = metrics_refined_df['kernel'].values\n",
    "\n",
    "# Plot kernels\n",
    "sns.scatterplot(data=metrics_refined_df, x=\"ii_global\", y=\"it\", hue=\"kernel\", marker='^', color='black', ax=axs, s=150)\n",
    "# for i, name in enumerate(kernel_names):\n",
    "    # plt.annotate(name, (instruction_intensity[i], instruction_throughput[i]), fontsize=9)\n",
    "\n",
    "# Set log-log scale\n",
    "axs.set_xscale(\"log\")\n",
    "axs.set_yscale(\"log\")\n",
    "\n",
    "# print text values\n",
    "# axs.text(2, peak_nofma + 500, f\"{peak_nofma} Ginstr\", fontsize=FONTSIZE-8, color='black')\n",
    "\n",
    "# Labels and legend\n",
    "axs.set_xlabel(\"Instruction Intensity (Instr/Byte)\")\n",
    "axs.set_ylabel(\"Instruction Throughput\\n(GInstr/s)\")\n",
    "axs.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "axs.grid(False)\n",
    "axs.set_xlim(1e-2, axs.get_xlim()[1])\n",
    "set_font_size(axs, FONTSIZE)\n",
    "\n",
    "axs.legend(fontsize=FONTSIZE - 2)\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/roofline.pdf', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 10\n",
    "Comparison of SIGMo with other CPU and GPU state-of-the-art subgraph isomorphism frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sota_df = pd.DataFrame(columns=['benchmark','total_time','first_solution_time','matches',])\n",
    "benchmarks = ['VF3', 'GSI', 'CuTS']\n",
    "\n",
    "# get the best result (lowest time for find all) from the sigmo_df\n",
    "best_result_find_all = min(sigmo_df[sigmo_df['find_all']].itertuples(), key=lambda x: x.total_time)\n",
    "result_find_first = min(sigmo_df[~sigmo_df['find_all']].itertuples(), key=lambda x: x.total_time)\n",
    "\n",
    "sota_df.loc[len(sota_df)] = ['SIGMo', best_result_find_all.total_time / 1000, result_find_first.total_time / 1000, best_result_find_all.n_matches]\n",
    "for b in benchmarks:\n",
    "  benchmark = b\n",
    "  total_time = 0\n",
    "  first_solution_time = 0\n",
    "  matches = 0\n",
    "  with open(f'./out/{b}/{b}.txt') as f:\n",
    "    for line in f:\n",
    "      if line.startswith('Total time (s):'):\n",
    "        total_time = float(line.split(' ')[-1])\n",
    "      elif line.startswith('First match time (s):'):\n",
    "        first_solution_time = float(line.split(' ')[-1])\n",
    "      elif line.startswith('Total matches:'):\n",
    "        matches = int(line.split(' ')[-1].replace(',', ''))\n",
    "      if first_solution_time == total_time:\n",
    "        first_solution_time = 0\n",
    "  sota_df.loc[len(sota_df)] = [benchmark, total_time, first_solution_time, matches]\n",
    "  \n",
    "sota_df['throughput'] = sota_df['matches'] / sota_df['total_time']\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 10 (a)\n",
    "Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 5))\n",
    "FONTSIZE=20\n",
    "set_font_size(axs, 20)\n",
    "\n",
    "axs.bar(sota_df['benchmark'], sota_df['total_time'], color=['lightgray', 'lightgray', 'lightgray'], edgecolor='black')\n",
    "axs.bar(sota_df['benchmark'], sota_df['first_solution_time'], hatch='///', color=['lightgray', 'lightgray', 'lightgray'], edgecolor='black')\n",
    "\n",
    "positions = []\n",
    "for i, row in sota_df.iterrows():\n",
    "    if row['first_solution_time'] == 0:\n",
    "        positions.append((i, row['total_time']))\n",
    "\n",
    "# # Annotate the text only once\n",
    "# if positions:\n",
    "#     first_position = positions[0]\n",
    "#     axs.text(first_position[0] - 1.5, first_position[1] / 12, \n",
    "#              'Always find\\nall matches', \n",
    "#              ha='center', va='bottom',\n",
    "#              fontsize=FONTSIZE)  # Center the text horizontally and align it vertically at the bottom\n",
    "\n",
    "#     # Create arrows for all positions\n",
    "#     for pos in positions:\n",
    "#         axs.annotate('', \n",
    "#                      xy=(pos[0] - .3, pos[1] / 2), \n",
    "#                      xytext=(first_position[0] - 1, first_position[1] / 6),  # Point to the same text position\n",
    "#                      arrowprops=dict(facecolor='black', shrink=0.005))\n",
    "\n",
    "axs.annotate(\"Our\\napproach\", \n",
    "             xy=(0, sota_df.loc[0, 'total_time'] + 2), \n",
    "             xytext=(0, sota_df.loc[0, 'total_time'] + 15), \n",
    "             ha='center', va='bottom',  # Center the text horizontally and align it vertically at the bottom\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "             fontsize=FONTSIZE)\n",
    "\n",
    "# write the time on top of each bar\n",
    "for i, row in sota_df.iterrows():\n",
    "  axs.text(i, row['total_time'] + row['total_time'] * 0.02,\n",
    "           f'{row[\"total_time\"]:.2f}', \n",
    "           ha='center', \n",
    "           va='bottom', \n",
    "           color='black', \n",
    "          #  fontweight='bold',\n",
    "           fontsize=FONTSIZE\n",
    "           )\n",
    "\n",
    "axs.set_yscale('log', base=10, subs=[2, 3, 4, 5, 6, 7, 8, 9])\n",
    "axs.set_ylabel('Time (s)')\n",
    "axs.set_xlabel('')\n",
    "\n",
    "axs.legend(['Find All', 'Find First'], loc='upper left', fontsize=FONTSIZE-4)\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/sota_time.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 10 (b)\n",
    "Throughput (Matches per second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 5))\n",
    "FONTSIZE=20\n",
    "set_font_size(axs, 20)\n",
    "axs.bar(sota_df['benchmark'], sota_df['throughput'], color=['lightgray', 'lightgray', 'lightgray'], edgecolor='black')\n",
    "\n",
    "axs.annotate(\"Our approach\", \n",
    "             xy=(0.4, sota_df.loc[0, 'throughput'] - sota_df.loc[0, 'throughput'] * 0.8), \n",
    "             xytext=(1.5, sota_df.loc[0, 'throughput'] - sota_df.loc[0, 'throughput'] * 0.5), \n",
    "             ha='center', va='bottom',  # Center the text horizontally and align it vertically at the bottom\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "             fontsize=FONTSIZE)\n",
    "\n",
    "# write the time on top of each bar\n",
    "for i, row in sota_df.iterrows():\n",
    "  thorughput_string = f'{row[\"throughput\"]:.2e}'\n",
    "  a, b = thorughput_string.split('e+0')\n",
    "  thorughput_string = rf'{a}$\\times 10^{b}$'\n",
    "  # thorughput_string = thorughput_string.replace('e+0', '\\nx10^').replace('e+', ' x 10^').replace('e-0', ' / 10^').replace('e-', ' / 10^')\n",
    "  axs.text(i, row['throughput'] + row['throughput'] * 0.005,\n",
    "           thorughput_string,\n",
    "           ha='center', \n",
    "           va='bottom', \n",
    "           color='black', \n",
    "          #  fontweight='bold',\n",
    "           fontsize=FONTSIZE\n",
    "           )\n",
    "\n",
    "axs.set_ylabel('Throughput (matches/s)')\n",
    "axs.set_xlabel('')\n",
    "axs.set_yscale('log', base=10, subs=[2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/sota_throughput.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 11\n",
    "Filter, join, and total execution times of SIGMo on NVIDIA V100S, AMD MI100, and Intel Max 1100 GPUs. The total time includes an arrow indicating the fastest execution for each GPU.\n",
    "\n",
    "**Instructions to reproduce**:\n",
    "1. Execute SIGMo on each hardware;\n",
    "2. Collect the output csv in the ./out/SIGMO folder, and name each file according to the manufacturer (e.g. sigmo_results_nvidia.csv, sigmo_results_amd.csv, sigmo_results_intel.csv)\n",
    "3. Run the following cell;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_df = pd.read_csv('./out/SIGMO/sigmo_results_nvidia.csv')\n",
    "amd_df = pd.read_csv('./out/SIGMO/sigmo_results_amd.csv')\n",
    "amd_df['total_time'] = amd_df['filter_gpu_time'] + amd_df['join_gpu_time']\n",
    "intel_df = pd.read_csv('./out/SIGMO/sigmo_results_intel.csv')\n",
    "intel_df['total_time'] = intel_df['filter_gpu_time'] + intel_df['join_gpu_time']\n",
    "\n",
    "\n",
    "nvidia_df['GPU'] = 'NVIDIA V100S'\n",
    "amd_df['GPU'] = 'AMD MI100'\n",
    "intel_df['GPU'] = 'Intel Max 1100'\n",
    "\n",
    "scale_df = pd.concat([nvidia_df, amd_df, intel_df])\n",
    "scale_df = scale_df[scale_df['find_all']]\n",
    "scale_df = scale_df.sort_values(by='n_refinement_steps')\n",
    "scale_df['n_refinement_steps'] += 1\n",
    "\n",
    "# Create a DataFrame\n",
    "iterations = list(range(1, len(filter_time) + 1))\n",
    "\n",
    "scale_df['filter_gpu_time'] /= 1000\n",
    "scale_df['mapping_host_time'] /= 1000\n",
    "scale_df['join_gpu_time'] /= 1000\n",
    "scale_df['total_gpu_time'] = scale_df['filter_gpu_time'] + scale_df['join_gpu_time']\n",
    "scale_df['total_time'] /= 1000\n",
    "\n",
    "filter_df = scale_df[['n_refinement_steps', 'filter_gpu_time', 'GPU']].copy()\n",
    "filter_df['type'] = 'Filter'\n",
    "filter_df.rename(columns={'filter_gpu_time': 'time'}, inplace=True)\n",
    "\n",
    "join_df = scale_df[['n_refinement_steps', 'join_gpu_time', 'GPU']].copy()\n",
    "join_df['type'] = 'Join'\n",
    "join_df.rename(columns={'join_gpu_time': 'time'}, inplace=True)\n",
    "\n",
    "total_df = scale_df[['n_refinement_steps', 'total_time', 'GPU']].copy()\n",
    "total_df['type'] = 'Total'\n",
    "total_df.rename(columns={'total_time': 'time'}, inplace=True)\n",
    "scale_df = pd.concat([filter_df, join_df, total_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 18\n",
    "EDGE_COLOR = '#4F4F4F'\n",
    "PALETTE = ('#76B900', '#FF6F00', '#0071C5')\n",
    "\n",
    "hue_order = ['NVIDIA V100S', 'AMD MI100', 'Intel Max 1100']\n",
    "\n",
    "fg = sns.FacetGrid(scale_df, row='type', hue_order=['Filter', 'Join', 'Total'], height=2, aspect=3.5, sharex=True, sharey=False)\n",
    "for ax, title in zip(fg.axes.flat, scale_df['type'].unique()):\n",
    "  ax.annotate(title, xy=(1.02, 0.5), xycoords='axes fraction', fontsize=FONTSIZE, ha='left', va='center', rotation=270)\n",
    "fg.set_titles('')\n",
    "fg.map(sns.barplot, 'n_refinement_steps', 'time', 'GPU', hue_order=hue_order, palette=PALETTE, edgecolor=EDGE_COLOR)\n",
    "  \n",
    "total_ax = fg.axes.flat[-1]\n",
    "mins = {}\n",
    "for patch in total_ax.patches:\n",
    "  height = patch.get_height()\n",
    "  if height == 0: continue\n",
    "  color = patch.get_facecolor()\n",
    "  if color not in mins:\n",
    "    mins[color] = height\n",
    "  else:\n",
    "    mins[color] = min(mins[color], height)\n",
    "\n",
    "for patch in total_ax.patches:\n",
    "  height = patch.get_height()\n",
    "  if height == 0: continue\n",
    "  color = patch.get_facecolor()\n",
    "  if height == mins[color]:\n",
    "    total_ax.annotate(f'{height:.2f}', \n",
    "                      xytext=(patch.get_x() + patch.get_width() / 2, height + height * 2.5), \n",
    "                      ha='center', \n",
    "                      va='bottom', \n",
    "                      xy=(patch.get_x() + patch.get_width() / 2, height),\n",
    "                      fontsize=FONTSIZE-2,\n",
    "                      arrowprops=dict(facecolor=color, shrink=0.05))\n",
    "    \n",
    "fg.add_legend(handles=fg._legend_data.values(), title='', fontsize=FONTSIZE-2, loc='upper left', bbox_transform=fg.axes.flat[0].transAxes, bbox_to_anchor=(0.005, 1.1))\n",
    "for ax in fg.axes.flat:\n",
    "  set_font_size(ax, FONTSIZE)\n",
    "  ax.set_ylabel('')\n",
    "\n",
    "# add only one y label to the leftmost plot\n",
    "fg.axes.flat[1].set_ylabel('Time (s)')\n",
    "fg.set_xlabels('Refinement Iterations')\n",
    "fg.tight_layout()\n",
    "fg.savefig('./out/plots/filter_join_time_facet.pdf')\n",
    "fg.figure.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 12\n",
    "Single-GPU scalability of SIGMo in both â€˜Find Allâ€™ and â€˜Find Firstâ€™ modes. The plot shows how the performance scale by increasing the dataset size. The bottom x-axis represents the size of the data graphs, while the top x-axis indicates the corresponding dataset scale factors. Numbers along each line denote the relative execution time compared to the baseline (first execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "scale_df = pd.DataFrame(columns=['scale', 'filter_time', 'join_time', 'total_time', 'matches', 'find-all'])\n",
    "\n",
    "for file in glob.glob('./out/SIGMO/logs/dataset_scale/logs_*.log'):\n",
    "  filter_times = []\n",
    "  join_times = []\n",
    "  total_times = []\n",
    "  matches = []\n",
    "  with open(file) as f:\n",
    "    host_results = False\n",
    "    for line in f.readlines():\n",
    "      if 'Overall Host Stats' in line:\n",
    "        host_results = True\n",
    "      elif line.startswith('Filter time:') and host_results:\n",
    "        filter_times.append(float(line.split(' ')[-2]))\n",
    "      elif line.startswith('Join time:') and host_results:\n",
    "        join_times.append(float(line.split(' ')[-2]))\n",
    "      elif line.startswith('Total time:') and host_results:\n",
    "        total_times.append(float(line.split(' ')[-2]))\n",
    "      elif line.startswith('# Matches:') and host_results:\n",
    "        matches.append(int(line.split(' ')[-1].replace('.',''))) \n",
    "        host_results = False\n",
    "  findall = 'findall' in file\n",
    "  scale = file.split('_')[-1].split('.')[0]\n",
    "  for f, j, t, m in zip(filter_times, join_times, total_times, matches):\n",
    "    scale_df.loc[len(scale_df)] = [scale, f, j, t, m, findall]\n",
    "\n",
    "scale_df['filter_time'] /= 1000\n",
    "scale_df['join_time'] /= 1000\n",
    "scale_df['total_time'] /= 1000\n",
    "scale_df['throughput'] = scale_df['matches'] / scale_df['total_time']\n",
    "\n",
    "DATA_GRAPHS_NODES = 2_745_872\n",
    "scale_df['scale'] = scale_df['scale'].astype(int) * DATA_GRAPHS_NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 15\n",
    "\n",
    "# Sort for consistent plotting\n",
    "scale_df.sort_values(by='scale', inplace=True)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot using mean and std (original style)\n",
    "sns.lineplot(data=scale_df[scale_df['find-all']], x='scale', y='total_time', errorbar='sd',\n",
    "             marker='o', markersize=10, ax=axs, label='Find All', color='gray')\n",
    "\n",
    "sns.lineplot(data=scale_df[~scale_df['find-all']], x='scale', y='total_time', errorbar='sd',\n",
    "             marker='^', markersize=10, ax=axs, label='Find First', color='gray', linestyle='--')\n",
    "\n",
    "# X-axis ticks and labels\n",
    "xticks = list(scale_df['scale'].unique())\n",
    "xticks.append(xticks[-1] + DATA_GRAPHS_NODES) \n",
    "xtick_labels = [f'{int(x / 1e6)}\\n' for i, x in enumerate(xticks, 1)]\n",
    "axs.set_xticks(xticks)\n",
    "axs.set_xticklabels(xtick_labels)\n",
    "axs.set_xlabel(r'# Total Data Nodes $(\\times 10^6)$')\n",
    "axs.set_ylabel('Total Time (s)')\n",
    "\n",
    "axs.axvline(x=xticks[-1], color='red', linestyle='--', linewidth=1.5)\n",
    "# Annotate \"Out of Memory\" on the plot\n",
    "axs.text(xticks[-1] - ((xticks[-1] - xticks[-2]) * 0.2), axs.get_ylim()[1] * .5, 'Out of Memory', color='red',\n",
    "         fontsize=FONTSIZE, ha='center', va='center', rotation=90)\n",
    "\n",
    "\n",
    "# Extend x-axis limits to ensure the last tick is visible\n",
    "xlims = axs.get_xlim()\n",
    "axs.set_xlim(left=xlims[0], right=xticks[-1] + (xticks[-1] - xticks[-2]) * 0.2)\n",
    "axs.set_ylim(bottom=0, top=max(scale_df['total_time']) * 1.1)\n",
    "\n",
    "# Compute medians separately for label annotations\n",
    "df_median = scale_df.groupby(['scale', 'find-all'], as_index=False)['total_time'].median()\n",
    "\n",
    "# Add normalized values (based on median)\n",
    "print = True\n",
    "label_data = df_median[df_median['find-all'] == True].sort_values(by='scale')\n",
    "base_time = label_data['total_time'].iloc[0]\n",
    "for i, (x, y) in enumerate(zip(label_data['scale'], label_data['total_time'])):\n",
    "    ratio = y / base_time\n",
    "    if print:\n",
    "        axs.text(x, y + 0.5, f'Ã—{ratio:.1f}', ha='center', va='bottom', fontsize=FONTSIZE-4, color='black')\n",
    "        print = False\n",
    "    else:\n",
    "        print = True\n",
    "print = False\n",
    "label_data = df_median[df_median['find-all'] == False].sort_values(by='scale')\n",
    "base_time = label_data['total_time'].iloc[0]\n",
    "for i, (x, y) in enumerate(zip(label_data['scale'], label_data['total_time'])):\n",
    "    if i == 1:\n",
    "        continue\n",
    "    ratio = y / base_time\n",
    "    if print:\n",
    "        axs.text(x, y + 0.5, f'Ã—{ratio:.1f}', ha='center', va='bottom', fontsize=FONTSIZE-4, color='black')\n",
    "        print = False\n",
    "    else:\n",
    "        print = True\n",
    "\n",
    "t_axs = axs.twiny()\n",
    "t_axs.set_ylim(axs.get_ylim())\n",
    "t_axs.set_xticks(xticks)\n",
    "t_axs.set_xlim(axs.get_xlim())\n",
    "t_axs.grid(False)\n",
    "t_axs.set_xticklabels([f'{i + 1}' for i in range(len(xticks))], fontsize=FONTSIZE, color='gray')\n",
    "# remove ticks\n",
    "t_axs.tick_params(axis='x', which='both', bottom=False, top=False)\n",
    "t_axs.set_xlabel('Dataset Scale Factor', fontsize=FONTSIZE, color='gray')\n",
    "\n",
    "# reduce the space between the xlabel and the xticks\n",
    "t_axs.xaxis.labelpad = 10\n",
    "axs.xaxis.labelpad = -5\n",
    "\n",
    "# Final touches\n",
    "axs.legend(fontsize=FONTSIZE, loc='upper left')\n",
    "set_font_size(axs, FONTSIZE)\n",
    "set_font_size(t_axs, FONTSIZE)\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/single_node_scale_time.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 13\n",
    "Execution of SIGMo on a multi-node environment with up to 256 NVIDIA A100 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_df = pd.DataFrame(columns=['nodes', 'graphs', 'time', 'matches', 'find-all'])\n",
    "for file in glob.glob('./out/SIGMO/logs/mpi/sigmo_*.log'):\n",
    "  fname = file.split('/')[-1].split('.')[0]\n",
    "  find_all = False\n",
    "  if '_findall' in fname:\n",
    "    find_all = True\n",
    "    fname = fname.replace('_findall', '')\n",
    "  nodes = int(fname.replace('sigmo_mpi_', ''))\n",
    "  time = 0\n",
    "  matches = 0\n",
    "  graphs = 0\n",
    "  with open(file) as f:\n",
    "    for line in f:\n",
    "      if line.startswith('# Total Data Nodes'):\n",
    "        graphs = int(line.split(' ')[-1])\n",
    "      elif line.startswith('MPI time:'):\n",
    "        time = int(line.split(' ')[-2])\n",
    "      elif line.startswith('# Total matches:'):\n",
    "        matches = int(line.split(' ')[-1].replace('.', ''))\n",
    "  scale_df.loc[len(scale_df)] = [nodes, graphs, time, matches, find_all]\n",
    "\n",
    "scale_df['time'] = scale_df['time'].astype(int) / 1000\n",
    "scale_df['throughput'] = scale_df['matches'] / scale_df['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 13(a)\n",
    "Execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 18\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(4.5, 4.5))\n",
    "scale_df.sort_values(by='nodes', inplace=True)\n",
    "\n",
    "g = sns.lineplot(data=scale_df[scale_df['find-all']], x='nodes', y='time', ax=axs, marker='o', markersize=10, color='gray')\n",
    "g = sns.lineplot(data=scale_df[~scale_df['find-all']], x='nodes', y='time', ax=axs, marker='^', markersize=10, color='gray', linestyle='--')\n",
    "axs.set_xticks(scale_df['nodes'].unique())\n",
    "axs.set_ylabel('Time (s)')\n",
    "axs.set_xlabel('# GPUs')\n",
    "axs.set_xscale('log', base=2)\n",
    "axs.set_xticklabels([str(int(x)*4) for x in axs.get_xticks()])\n",
    "\n",
    "set_font_size(axs, FONTSIZE)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/sigmo_mpi_time.pdf', dpi=300)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 13(b)\n",
    "Throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 18\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "def billions_formatter(x, pos):\n",
    "  return f'{x // 1e9:.0f}'  # e.g. '1.2' for 1.2e9\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(4.5, 4.5))\n",
    "scale_df.sort_values(by='nodes', inplace=True)\n",
    "\n",
    "g = sns.lineplot(data=scale_df[scale_df['find-all']], x='nodes', y='throughput', ax=axs, marker='o', markersize=10, color='gray', label='Find All')\n",
    "g = sns.lineplot(data=scale_df[~scale_df['find-all']], x='nodes', y='throughput', ax=axs, marker='^', markersize=10, color='gray', linestyle='--', label='Find First')\n",
    "axs.set_xticks(scale_df['nodes'].unique())\n",
    "axs.set_xscale('log', base=2)\n",
    "axs.set_xticklabels([str(int(x)*4) for x in axs.get_xticks()])\n",
    "axs.set_yscale('log', base=2, subs=[2, 3, 4, 5, 6, 7, 8, 9])\n",
    "axs.set_ylabel('Throughput (matches/s)')\n",
    "axs.set_xlabel('# GPUs')\n",
    "\n",
    "# axs.yaxis.set_major_formatter(ticker.FuncFormatter(billions_formatter))\n",
    "axs.set_ylabel(r'Throughput (matches/s)')  # or \"Throughput (billions of matches/s)\"\n",
    "axs.legend(loc='upper left', fontsize=FONTSIZE-2)\n",
    "set_font_size(axs, FONTSIZE)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/sigmo_mpi_throughput.pdf')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 14\n",
    "Runtime of each MPI process on 256 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r\"^\\s*Rank\\s+(\\d+):\\s+(\\d+)\\s+ms\")\n",
    "scale_df = pd.DataFrame(columns=['rank', 'time', 'find-all'])\n",
    "for file in glob.glob('./out/SIGMO/logs/mpi/sigmo_mpi_64*.log'):\n",
    "  fname = file.split('/')[-1].split('.')[0]\n",
    "  find_all = False\n",
    "  if '_findall' in fname:\n",
    "    find_all = True\n",
    "    fname = fname.replace('_findall', '')\n",
    "  nodes = int(fname.replace('sigmo_mpi_', ''))\n",
    "  \n",
    "  with open(file) as f:\n",
    "    for line in f:\n",
    "      if \"Rank\" in line:\n",
    "        groups = pattern.findall(line)\n",
    "        if groups:\n",
    "          rank, time = groups[0]\n",
    "          scale_df.loc[len(scale_df)] = [rank, time, find_all]\n",
    "          \n",
    "\n",
    "\n",
    "scale_df['time'] = scale_df['time'].astype(int) / 1000\n",
    "scale_df['rank'] = scale_df['rank'].astype(int)\n",
    "\n",
    "# Ensure the 'rank' column contains all values from 0 to 255\n",
    "all_ranks = pd.DataFrame(columns=['rank', 'find-all'])\n",
    "for i in range(256):\n",
    "    all_ranks.loc[len(all_ranks)] = [i, False]\n",
    "    all_ranks.loc[len(all_ranks)] = [i, True]\n",
    "    \n",
    "# Merge with the existing DataFrame to identify missing ranks\n",
    "scale_df = pd.merge(all_ranks, scale_df, on=['rank', 'find-all'], how='left')\n",
    "\n",
    "scale_df['time'] = scale_df.groupby('find-all')['time'].ffill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 18\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "scale_df.to_csv('tmp.csv', index=False)\n",
    "\n",
    "# sns.scatterplot(data=df, x='rank', y='time', style='find-all', ax=axs, color='gray', markers=['^', 'o'], alpha=1, s=70, linewidth=0.5)\n",
    "sns.barplot(data=scale_df, x='rank', y='time', hue='find-all', hue_order=[False, True], ax=axs, palette='dark:lightgray', alpha=.5, edgecolor='black', linewidth=0.5, dodge=True)\n",
    "\n",
    "# Add horizontal lines for the highest dot in both 'find-all' and 'not'\n",
    "max_time_find_all = scale_df[scale_df['find-all'] == True]['time'].max()\n",
    "max_time_not_find_all = scale_df[scale_df['find-all'] == False]['time'].max()\n",
    "\n",
    "\n",
    "# axs.axhline(max_time_find_all, linestyle='--', label='Max find-all', color='tab:red', linewidth=2, alpha=1)\n",
    "# axs.text(255//2, max_time_find_all, f'Find All Barrier', ha='center', va='bottom', fontsize=FONTSIZE-6, color='black')\n",
    "# axs.axhline(max_time_not_find_all, linestyle='--', label='Max not find-all', color='tab:red', linewidth=2, alpha=1)\n",
    "# axs.text(255//2, max_time_not_find_all, f'Find First Barrier', ha='center', va='bottom', fontsize=FONTSIZE-6, color='black')\n",
    "\n",
    "# get legend handles\n",
    "axs.set_xticks([0, 31, 63, 95, 127, 159, 191, 223, 255])\n",
    "axs.set_xticklabels([0, '...', 63, '...', 127, '...', 191, '...', 255])\n",
    "\n",
    "axs.set_xlabel('GPU ID')\n",
    "axs.set_ylabel('Time (s)')\n",
    "set_font_size(axs, FONTSIZE)\n",
    "\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "# handles[0].set_markersize(10)\n",
    "# handles[1].set_markersize(10)\n",
    "handles[0], handles[1] = handles[1], handles[0] \n",
    "\n",
    "# display the legend in a single row\n",
    "# axs.legend(handles[:2], ['Find All', 'Find First', 'MPI Barrier'], \n",
    "#            loc='upper center', fontsize=FONTSIZE-4, ncol=4, \n",
    "#            bbox_to_anchor=(0.5, 1.15), frameon=False)\n",
    "\n",
    "axs.legend(handles[:2], ['Find All', 'Find First'],\n",
    "           loc='upper right', fontsize=FONTSIZE-4, ncol=2, frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./out/plots/sigmo_mpi_barrier.pdf', dpi=300)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
